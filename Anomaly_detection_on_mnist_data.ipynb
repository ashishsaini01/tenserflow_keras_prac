{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anomaly_detection_on_mnist_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNN9ZK5AIfcH6yvNoA0UXxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishsaini01/tenserflow_keras_prac/blob/master/Anomaly_detection_on_mnist_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BTxcSm0npNXU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (c_test, _) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK64lr7HpjGE",
        "outputId": "2b80edc3-29e4-496d-ce03-226fbdbd0440"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# minimize the data and reshape it to 28*28*1\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = c_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
      ],
      "metadata": {
        "id": "11GtOB5Op15k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the encoder and decoder\n",
        "\n",
        "# pass the grey scale image\n",
        "inputs = tf.keras.Input(shape = (28, 28, 1), name = 'input_layer')\n",
        "\n",
        "# conv block1\n",
        "encoded = tf.keras.layers.Conv2D(32, kernel_size  = 3, strides = 1, padding = 'same',  name = 'conv1')(inputs)\n",
        "encoded = tf.keras.layers.BatchNormalization(name = 'batch_nor_1')(encoded)\n",
        "encoded = tf.keras.layers.LeakyReLU(name = 'leaky_relu_1')(encoded)\n",
        "\n",
        "# conv block 2\n",
        "encoded = tf.keras.layers.Conv2D(64, kernel_size = 3, strides = 2, padding = 'same', name = 'conv2')(encoded)\n",
        "encoded = tf.keras.layers.BatchNormalization(name = 'batch_norm2')(encoded)\n",
        "encoded = tf.keras.layers.LeakyReLU(name = 'leaky_relu_2')(encoded)\n",
        "\n",
        "# conv block 3\n",
        "encoded = tf.keras.layers.Conv2D(64, kernel_size = 3, strides = 2, padding = 'same', name = 'conv3')(encoded)\n",
        "encoded = tf.keras.layers.BatchNormalization(name = 'batch_norm3')(encoded)\n",
        "encoded = tf.keras.layers.LeakyReLU(name = 'leaky_relu_3')(encoded)\n",
        "\n",
        "# Decoder\n",
        "# decode conv block 1\n",
        "decoded = tf.keras.layers.Conv2DTranspose(64, kernel_size = 3, strides = 1, padding = 'same', name = 'deconv1')(encoded)\n",
        "decoded = tf.keras.layers.BatchNormalization(name = 'batch_norm4')(decoded)\n",
        "decoded = tf.keras.layers.LeakyReLU(name = 'leaky_relu_4')(decoded)\n",
        "\n",
        "# decode conv block 2\n",
        "decoded = tf.keras.layers.Conv2DTranspose(64, 3, strides = 2, padding = 'same', name = 'deconv2')(decoded)\n",
        "decoded = tf.keras.layers.BatchNormalization(name = 'batch_norm5')(decoded)\n",
        "deocded = tf.keras.layers.LeakyReLU(name = 'leaky_relu_5')(decoded)\n",
        "\n",
        "# decode conv block 3\n",
        "decoded = tf.keras.layers.Conv2DTranspose(32, 3, 2, padding = 'same', name = 'deconv3')(decoded)\n",
        "decoded = tf.keras.layers.BatchNormalization(name = 'batch_norm6')(decoded)\n",
        "decoded = tf.keras.layers.LeakyReLU(name = 'leaky_relu_6')(decoded)\n",
        "\n",
        "# outputs\n",
        "output = tf.keras.layers.Conv2DTranspose(1, 3, 1, padding = 'same', activation = 'sigmoid', name = 'output_conv')(decoded)"
      ],
      "metadata": {
        "id": "QfNPz77Vqyrv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ssim loss function\n",
        "def SSIMLoss(y_true, y_pred):\n",
        "  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))"
      ],
      "metadata": {
        "id": "deASnmng2ND7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = tf.keras.Model(inputs, output)\n",
        "optimizer = tf.keras.optimizers.Adam(lr = 0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=SSIMLoss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A44Suc_q2yXg",
        "outputId": "87f788f6-e99a-4f1e-9e68-ee9ca862ddb9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist=autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test)\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itc3Up7J2014",
        "outputId": "0b199ef4-439c-4ac5-a23a-eb9ea527e9cc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 369s 780ms/step - loss: 0.1173 - val_loss: 0.5962\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 353s 754ms/step - loss: 8.0176e-04 - val_loss: 0.7440\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 354s 754ms/step - loss: 5.8993e-04 - val_loss: 0.7585\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 352s 751ms/step - loss: 4.4022e-04 - val_loss: 0.7383\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 353s 753ms/step - loss: 3.7902e-04 - val_loss: 0.7377\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 353s 753ms/step - loss: 3.4253e-04 - val_loss: 0.7541\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 354s 754ms/step - loss: 3.0680e-04 - val_loss: 0.8237\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 353s 752ms/step - loss: 2.4549e-04 - val_loss: 0.8571\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 349s 744ms/step - loss: 2.2289e-04 - val_loss: 0.8700\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 351s 747ms/step - loss: 1.8981e-04 - val_loss: 0.8948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# autoencoder.predict(x_test)"
      ],
      "metadata": {
        "id": "ApmZosR525yK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### references\n",
        "# https://medium.com/analytics-vidhya/image-anomaly-detection-using-autoencoders-ae937c7fd2d1\n",
        "# https://blog.keras.io/building-autoencoders-in-keras.html"
      ],
      "metadata": {
        "id": "tQCuTmzEEnoL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7yjBwwZHOxhi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}